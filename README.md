# ğŸš¢ Titanic - Machine Learning from Disaster ğŸ§ 

Welcome to this comprehensive notebook that tackles the classic **Titanic survival prediction** problem from [Kaggle's Titanic competition](https://www.kaggle.com/c/titanic). This project covers the end-to-end data science workflow: from data exploration to model evaluation.
[View Notebook Here](https://github.com/amansagar88/Survival-of-passengers-of-titanic/blob/main/titanic-competition-eda-and-prediction.ipynb)

---

## ğŸ“Œ Project Overview

The goal of this notebook is to **predict whether a passenger survived or not**, based on features like age, gender, class, and more.

We apply:
- ğŸ“Š Exploratory Data Analysis (EDA)
- ğŸ§¹ Data Cleaning & Preprocessing
- ğŸ” Feature Engineering
- ğŸ¤– Multiple ML Models
- ğŸ“ˆ Evaluation & Interpretation

---

## ğŸ“ Files Used

- `train.csv` - Contains labeled data to train the model
- `test.csv` - Unlabeled data used for final prediction

---

## ğŸ” EDA Highlights

- Visualized survival rates by **gender**, **class**, **family size**, and more
- Explored **missing values** and handled them intelligently
- Gained insights into how different features impact survival

---

## ğŸ› ï¸ Feature Engineering

âœ”ï¸ Created new features like:
- FamilySize  
- Title extraction from names  
- Age group bins  

âœ”ï¸ Handled missing data using strategies like:
- Median imputation
- Mode filling for categorical columns

---

## ğŸ¤– Models Implemented

- Logistic Regression
- K-Nearest Neighbors
- Decision Trees
- Random Forest
- Support Vector Machine
- Gradient Boosting
- XGBoost

Each model was trained and evaluated using standard metrics. The best-performing model was selected based on accuracy and interpretability.

---

## ğŸ§ª Evaluation Metrics

I used:
- âœ… Accuracy
- ğŸ“Š Confusion Matrix
- ğŸ“ Classification Report

**Cross-validation** and **grid search** were applied for hyperparameter tuning (where applicable).

---

## ğŸ“Œ Results Summary

The notebook concludes with:
- A **model comparison**
- Insights on which features were most influential
- Final prediction output for submission

---

## ğŸš€ How to Use

1. Clone this repo or download the notebook
2. Upload it to Kaggle or run locally with the Titanic dataset
3. Walk through each section to understand the full ML pipeline

---

## âœ¨ Author

**Aman Sagar**  
ğŸ“« [View kaggle Profile](https://www.kaggle.com/sagaraman8)  
ğŸ” Data Scientist | ML Enthusiast

---

## ğŸ“ Acknowledgments

Thanks to:
- Kaggle community for discussions
- Open-source libraries: `pandas`, `sklearn`, `xgboost`, `matplotlib`, and `seaborn`

---

## ğŸ§  Takeaway

This notebook not only builds a strong Titanic survival predictor, but also demonstrates how to think like a data scientist â€” from hypothesis to validation. A must-practice problem for ML beginners!


